# The main job for sobeys
resources:
  jobs:
    wf_dih_meta_demo:
      run_as:
        user_name: skyler.myers@sobeys.com

      name: wf_dih_meta_demo

      # schedule:
      #   quartz_cron_expression: '44 37 8 * * ?'
      #   timezone_id: Europe/Amsterdam

      email_notifications:
        no_alert_for_skipped_runs: false
      webhook_notifications: {}
      timeout_seconds: 0
      max_concurrent_runs: 1

      tasks:
        - task_key: dataflow_spec
          run_if: ALL_SUCCESS
          notebook_task:
            notebook_path: "/Repos/skyler.myers@sobeys.com/sobeys_dih_meta/integration-tests/run_onboarding"
            source: WORKSPACE
          job_cluster_key: Job_cluster
          max_retries: 2
          min_retry_interval_millis: 600000
          retry_on_timemout: false
          timeout_seconds: 1800
          email_notifications: {}
          notification_settings:
            no_alert_for_skipped_runs: false
            no_alert_for_canceled_runs: false
            alert_on_last_attempt: false
            
        - task_key: dlt_bronze
          depends_on:
            - task_key: dataflow_spec
          run_if: ALL_SUCCESS
          pipeline_task:
            pipeline_id: ${resources.pipelines.dlt_bronze.id}
            full_refresh: true
          max_retries: 2
          min_retry_interval_millis: 600000
          retry_on_timemout: false
          timeout_seconds: 1800
          email_notifications: {}
          notification_settings:
            no_alert_for_skipped_runs: false
            no_alert_for_canceled_runs: false
            alert_on_last_attempt: false
        
        - task_key: dlt_silver
          depends_on:
            - task_key: dlt_bronze
          run_if: ALL_SUCCESS
          pipeline_task:
            pipeline_id: ${resources.pipelines.dlt_silver.id}
            full_refresh: true
          max_retries: 2
          min_retry_interval_millis: 600000
          retry_on_timemout: false
          timeout_seconds: 1800
          email_notifications: {}
          notification_settings:
            no_alert_for_skipped_runs: false
            no_alert_for_canceled_runs: false
            alert_on_last_attempt: false
        
        - task_key: ssot
          depends_on:
            - task_key: dlt_silver
          run_if: ALL_SUCCESS
          notebook_task:
            notebook_path: "/Repos/skyler.myers@sobeys.com/sobeys_dih_meta/src/ssot"
            source: WORKSPACE
          job_cluster_key: Job_cluster
          max_retries: 2
          min_retry_interval_millis: 600000
          retry_on_timemout: false
          timeout_seconds: 1800
          email_notifications: {}
          notification_settings:
            no_alert_for_skipped_runs: false
            no_alert_for_canceled_runs: false
            alert_on_last_attempt: false
            
          # python_wheel_task:
          #   package_name: sobeys
          #   entry_point: main
          # libraries:
            # By default we just include the .whl file generated for the sobeys package.
            # See https://docs.databricks.com/dev-tools/bundles/library-dependencies.html
            # for more information on how to add other libraries.
          #   - whl: ../dist/*.whl

      job_clusters:
        - job_cluster_key: Job_cluster
          new_cluster:
            spark_version: 14.0.x-scala2.12
            spark_conf:
              spark.databricks.delta.preview.enabled: 'true'
              spark.sql.shuffle.partitions: 'auto'
            azure_attributes:
              first_on_demand: 1
              availability: ON_DEMAND_AZURE
              spot_bid_max_price: -1
            node_type_id: Standard_D3_v2
            spark_env_vars:
              PYSPARK_PYTHON: "/databricks/python3/bin/python3"
            enable_elastic_disk: true
            data_security_mode: SINGLE_USER
            autoscale:
                min_workers: 1
                max_workers: 2

      format: MULTI_TASK
